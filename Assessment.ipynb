{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2683804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay, r2_score, mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88338f9f",
   "metadata": {},
   "source": [
    "## Carregando CDC Diabetes Health Indicators dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c8ef136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.93% de observações positivas de diabéticos. Há um Desequilibrio de classes nos dados.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "      <td>253680.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.429001</td>\n",
       "      <td>0.424121</td>\n",
       "      <td>0.962670</td>\n",
       "      <td>28.382364</td>\n",
       "      <td>0.443169</td>\n",
       "      <td>0.040571</td>\n",
       "      <td>0.094186</td>\n",
       "      <td>0.756544</td>\n",
       "      <td>0.634256</td>\n",
       "      <td>0.811420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951053</td>\n",
       "      <td>0.084177</td>\n",
       "      <td>2.511392</td>\n",
       "      <td>3.184772</td>\n",
       "      <td>4.242081</td>\n",
       "      <td>0.168224</td>\n",
       "      <td>0.440342</td>\n",
       "      <td>8.032119</td>\n",
       "      <td>5.050434</td>\n",
       "      <td>6.053875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.494934</td>\n",
       "      <td>0.494210</td>\n",
       "      <td>0.189571</td>\n",
       "      <td>6.608694</td>\n",
       "      <td>0.496761</td>\n",
       "      <td>0.197294</td>\n",
       "      <td>0.292087</td>\n",
       "      <td>0.429169</td>\n",
       "      <td>0.481639</td>\n",
       "      <td>0.391175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215759</td>\n",
       "      <td>0.277654</td>\n",
       "      <td>1.068477</td>\n",
       "      <td>7.412847</td>\n",
       "      <td>8.717951</td>\n",
       "      <td>0.374066</td>\n",
       "      <td>0.496429</td>\n",
       "      <td>3.054220</td>\n",
       "      <td>0.985774</td>\n",
       "      <td>2.071148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              HighBP       HighChol      CholCheck            BMI  \\\n",
       "count  253680.000000  253680.000000  253680.000000  253680.000000   \n",
       "mean        0.429001       0.424121       0.962670      28.382364   \n",
       "std         0.494934       0.494210       0.189571       6.608694   \n",
       "min         0.000000       0.000000       0.000000      12.000000   \n",
       "25%         0.000000       0.000000       1.000000      24.000000   \n",
       "50%         0.000000       0.000000       1.000000      27.000000   \n",
       "75%         1.000000       1.000000       1.000000      31.000000   \n",
       "max         1.000000       1.000000       1.000000      98.000000   \n",
       "\n",
       "              Smoker         Stroke  HeartDiseaseorAttack   PhysActivity  \\\n",
       "count  253680.000000  253680.000000         253680.000000  253680.000000   \n",
       "mean        0.443169       0.040571              0.094186       0.756544   \n",
       "std         0.496761       0.197294              0.292087       0.429169   \n",
       "min         0.000000       0.000000              0.000000       0.000000   \n",
       "25%         0.000000       0.000000              0.000000       1.000000   \n",
       "50%         0.000000       0.000000              0.000000       1.000000   \n",
       "75%         1.000000       0.000000              0.000000       1.000000   \n",
       "max         1.000000       1.000000              1.000000       1.000000   \n",
       "\n",
       "              Fruits        Veggies  ...  AnyHealthcare    NoDocbcCost  \\\n",
       "count  253680.000000  253680.000000  ...  253680.000000  253680.000000   \n",
       "mean        0.634256       0.811420  ...       0.951053       0.084177   \n",
       "std         0.481639       0.391175  ...       0.215759       0.277654   \n",
       "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
       "25%         0.000000       1.000000  ...       1.000000       0.000000   \n",
       "50%         1.000000       1.000000  ...       1.000000       0.000000   \n",
       "75%         1.000000       1.000000  ...       1.000000       0.000000   \n",
       "max         1.000000       1.000000  ...       1.000000       1.000000   \n",
       "\n",
       "             GenHlth       MentHlth       PhysHlth       DiffWalk  \\\n",
       "count  253680.000000  253680.000000  253680.000000  253680.000000   \n",
       "mean        2.511392       3.184772       4.242081       0.168224   \n",
       "std         1.068477       7.412847       8.717951       0.374066   \n",
       "min         1.000000       0.000000       0.000000       0.000000   \n",
       "25%         2.000000       0.000000       0.000000       0.000000   \n",
       "50%         2.000000       0.000000       0.000000       0.000000   \n",
       "75%         3.000000       2.000000       3.000000       0.000000   \n",
       "max         5.000000      30.000000      30.000000       1.000000   \n",
       "\n",
       "                 Sex            Age      Education         Income  \n",
       "count  253680.000000  253680.000000  253680.000000  253680.000000  \n",
       "mean        0.440342       8.032119       5.050434       6.053875  \n",
       "std         0.496429       3.054220       0.985774       2.071148  \n",
       "min         0.000000       1.000000       1.000000       1.000000  \n",
       "25%         0.000000       6.000000       4.000000       5.000000  \n",
       "50%         0.000000       8.000000       5.000000       7.000000  \n",
       "75%         1.000000      10.000000       6.000000       8.000000  \n",
       "max         1.000000      13.000000       6.000000       8.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdc_diabetes_health_indicators = fetch_ucirepo(id=891) \n",
    "   \n",
    "X = cdc_diabetes_health_indicators.data.features \n",
    "y = cdc_diabetes_health_indicators.data.targets \n",
    "  \n",
    "print(f\"{(100*(y.value_counts()[1] / y.count().iloc[0])):.2f}% de observações positivas de diabéticos. Há um Desequilibrio de classes nos dados.\")  \n",
    "X.columns\n",
    "\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3198b3",
   "metadata": {},
   "source": [
    "### Considerações Iniciais\n",
    "Por questões técnicas de capacidade computacional foi reduzido o volume de dados a 40% do valor original respeitando as proporções inicias dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a553c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduzido,X_restante ,y_reduzido ,y_restante = train_test_split(X, y, train_size=0.40, random_state=7, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93357b14",
   "metadata": {},
   "source": [
    "### 1. Estruturação Conceitual do Problema\n",
    "- Primeiramente o modelo supervisionado tem por caracteristica própria a tarefa de classificação e regressão, ou seja, necessita de features bem estruturadas (categorias numéricas, binarias e ordinais) e com um target (númerico, geralmente binário para classificações). Considerando o dataset CDC Diabetes Health Indicators e o Problema a ser tratado temos exatamente as mesmas características, features com características numéricas e computáveis e a necessidade de analisar novas observações para classificar a positividade da diabetes. Tudo isso se encaixa no modelo de treinamento supervisionado. \n",
    "- O treinamento deste modelo supervisionado consiste em encontrar parâmetros para o modelo que minimiza uma função de risco/erro para uma amostra de treinamento, baseado na diferença entre os valores previstos e reais das observações. São então encontrados algums desafios relevantes para o desenvolvimento do modelo de previsão, que são a baixa variância causada pelas muitas variaveis binarias além do problema de gerar uma regressão com estes dados, e temos o desequilibrio entre classes que consiste numa maior quantidade de observações de não diabeticos do que diabeticos (13.93% das observações) causando um tendencia a classificar como falso a presença de diabetes.\n",
    "- As bibliotecas python utilizadas mais relevantes são a biblioteca pandas, para a manipulação de dados como carregar, explorar e transformar DataFrames. A bibliteca Scikit-Learn, que tem uma gama de ferramentas e modelos, como normalização de dados, metricas e sorteadores de observação, para a efetivação do modelo de previsões almejado, pré-processamento dos dados e avalição do modelo. E a biblioteca Matplotlib, que é usada para visualizar os dados, distribuições e correlações."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a4b6c0",
   "metadata": {},
   "source": [
    "### 2. Implementação do Modelo K-Nearest Neighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420f33dc",
   "metadata": {},
   "source": [
    "- Algumas features foram escolhidas por relevância técnica no diagnostico médico para diabetes outras por representarem fatores de risco para se manifestar a diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0d02f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features explicativas\n",
    "features = [\n",
    "    'BMI',                  # Índice de Massa Corporal (contínuo)\n",
    "    'Age',                  # Idade (ordinal: 1-13 faixas etárias)\n",
    "    'HighBP',               # Hipertensão (binária)\n",
    "    'HighChol',             # Colesterol alto (binário)\n",
    "    'GenHlth',              # Saúde geral (ordinal: 1-5)\n",
    "    'HeartDiseaseorAttack', # Doença cardíaca (binária)\n",
    "    'PhysHlth',             # Saúde física ruim (contínuo: 0-30)\n",
    "    'DiffWalk',             # Dificuldade para caminhar (binária)\n",
    "    'Sex'                   # Gênero (binário)\n",
    "]\n",
    "\n",
    "# Já as features deixadas de fora ou são correlatas como BMI e Weight ou tem relevancia minima como AnyHealthCare (possuir plano de saúde)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb91dee",
   "metadata": {},
   "source": [
    "- Neste modelo se deve utilizar o estratificador no sorteamento de features para deixar constante a proporção entre casos positivos e negativos de diabetes.\n",
    "- Deve-se também normalizar as variáveis numéricas. Pois o modelo KNN é sensível a escalas, podendo ser prejudicado por diferentes escalas no mecanismo do algorítimo dos 'vizinhos mais próximos'.\n",
    "- Após a normalização há a hiperparametrização do modelo KNN pela variavel K, para achar o parâmetro mais adequado a solução do problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81f0862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_selecionado = X_reduzido[features] # Seleção das Features no Dataset inteiro\n",
    "\n",
    "# Sorteamento das observações com estratificação, proporção constante entre targets positivos e negativos a serem separados.\n",
    "X_treino,X_teste, y_treino,y_teste = train_test_split(X_selecionado,y_reduzido ,test_size=0.2, stratify=y_reduzido, random_state=7) \n",
    "y_treino= y_treino.values.ravel()\n",
    "y_teste = y_teste.values.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5106c2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        HighBP  HighChol  HeartDiseaseorAttack  DiffWalk  Sex       BMI  \\\n",
      "141850       0         1                     0         0    0  0.244236   \n",
      "221803       0         0                     0         0    0 -0.362213   \n",
      "215487       0         0                     0         0    0 -1.423497   \n",
      "39333        1         0                     0         0    1 -0.058989   \n",
      "101995       0         0                     1         0    1 -0.968661   \n",
      "...        ...       ...                   ...       ...  ...       ...   \n",
      "41189        1         1                     1         1    1  0.547460   \n",
      "18727        0         0                     0         0    1 -0.513825   \n",
      "140208       0         0                     0         0    1 -0.513825   \n",
      "131506       1         1                     0         0    0 -0.210601   \n",
      "199748       1         0                     0         0    1  0.244236   \n",
      "\n",
      "        PhysHlth   GenHlth       Age  \n",
      "141850 -0.487230 -0.480433 -0.011588  \n",
      "221803 -0.487230 -1.417709 -0.011588  \n",
      "215487 -0.487230 -1.417709 -1.323505  \n",
      "39333  -0.028481 -0.480433 -1.979463  \n",
      "101995 -0.487230 -0.480433  1.300330  \n",
      "...          ...       ...       ...  \n",
      "41189   2.953391  2.331397  1.300330  \n",
      "18727  -0.487230  1.394121 -0.667546  \n",
      "140208 -0.257856 -1.417709 -0.995525  \n",
      "131506 -0.487230  0.456844  0.972350  \n",
      "199748 -0.487230  0.456844  0.972350  \n",
      "\n",
      "[81177 rows x 9 columns]\n",
      "        HighBP  HighChol  HeartDiseaseorAttack  DiffWalk  Sex       BMI  \\\n",
      "48726        0         0                     0         0    1  0.840700   \n",
      "228028       0         0                     0         0    0 -0.365831   \n",
      "136179       1         1                     0         0    0 -0.064198   \n",
      "176596       0         0                     0         0    1 -0.818280   \n",
      "167569       1         0                     0         0    0 -0.365831   \n",
      "...        ...       ...                   ...       ...  ...       ...   \n",
      "176983       1         1                     0         0    0  0.539067   \n",
      "141379       1         0                     0         0    0 -1.421545   \n",
      "227086       1         1                     0         0    1  0.991516   \n",
      "155238       1         1                     0         0    1  0.539067   \n",
      "118289       0         0                     0         1    0 -0.818280   \n",
      "\n",
      "        PhysHlth   GenHlth       Age  \n",
      "48726   2.998287 -0.474997 -0.654712  \n",
      "228028 -0.482768 -1.417238  0.325810  \n",
      "136179 -0.482768 -0.474997  0.652651  \n",
      "176596 -0.482768 -0.474997  1.306332  \n",
      "167569 -0.482768 -0.474997 -1.308394  \n",
      "...          ...       ...       ...  \n",
      "176983  0.329478 -0.474997  0.325810  \n",
      "141379 -0.482768 -0.474997  0.325810  \n",
      "227086 -0.134663  2.351726  0.325810  \n",
      "155238 -0.134663  0.467244  0.979492  \n",
      "118289  0.097408  1.409485  0.652651  \n",
      "\n",
      "[20295 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "features_to_normalize = ['BMI', 'PhysHlth', 'GenHlth', 'Age'] # Features a serem normalizadas\n",
    "\n",
    "# Processo de Normalização do X_treino\n",
    "normalizador1 = StandardScaler()\n",
    "features_treino_normalizado = normalizador1.fit_transform(X_treino[features_to_normalize])\n",
    "features_treino_normalizado = pd.DataFrame(features_treino_normalizado, columns=normalizador1.get_feature_names_out(), index=X_treino.index)\n",
    "X_treino_normalizado = pd.concat([X_treino.drop(features_to_normalize, axis=1), features_treino_normalizado], axis=1)\n",
    "print(X_treino_normalizado)\n",
    "\n",
    "# Processo de Normalização do X_teste\n",
    "normalizador2 = StandardScaler()\n",
    "features_teste_normalizado = normalizador2.fit_transform(X_teste[features_to_normalize])\n",
    "features_teste_normalizado = pd.DataFrame(features_teste_normalizado, columns=normalizador2.get_feature_names_out(), index=X_teste.index)\n",
    "X_teste_normalizado = pd.concat([X_teste.drop(features_to_normalize, axis=1), features_teste_normalizado], axis=1)\n",
    "print(X_teste_normalizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d09d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "metricas_dict = {\n",
    "    'accuracy': accuracy_score,\n",
    "    'precision': precision_score,\n",
    "    'recall': recall_score,\n",
    "    'f1_score': f1_score\n",
    "}\n",
    "\n",
    "metricas_modelos = []\n",
    "\n",
    "# Treinamento e metricas de previsão de modelos KNN variando de 1 a 18\n",
    "Ks = [k for k in range(1,21,1)]\n",
    "for K in Ks:\n",
    "    modelo_KNN = KNeighborsClassifier(n_neighbors=K)\n",
    "    modelo_KNN.fit(X_treino_normalizado, y_treino)\n",
    "    \n",
    "    # Aquisição de cada Métrica para o Modelo.\n",
    "    for metrica in ['accuracy', 'precision', 'recall', 'f1_score']:\n",
    "        metrica_avaliada_treino = metricas_dict[metrica](y_treino, modelo_KNN.predict(X_treino_normalizado))\n",
    "        metrica_avaliada_teste = metricas_dict[metrica](y_teste, modelo_KNN.predict(X_teste_normalizado))\n",
    "        metricas_modelos.append({'K': K, 'stat' : 'treino', 'metrica': metrica , 'valor': metrica_avaliada_treino})\n",
    "        metricas_modelos.append({'K': K, 'stat' : 'teste', 'metrica': metrica, 'valor': metrica_avaliada_teste})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c508cb6",
   "metadata": {},
   "source": [
    "### Utilização da métricas\n",
    "- As métricas utilizadas como alicerce da análise são recall e acurácia.\n",
    "- A acurácia indica os acertos absolutos do sistema, tanto em treinamento quanto em teste.\n",
    "- Já o recall indica a porcentagem de resultados positivos para diabetes pelo total de positivos testado no modelo. Indicando quantos acertos positivos para a doença foram realizados. O que é importante na analise médica no caso de previsões acertivas da doença."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c148ff9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>stat</th>\n",
       "      <th colspan=\"3\" halign=\"left\">valor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>list</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.872738</td>\n",
       "      <td>0.893295</td>\n",
       "      <td>0.852180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.869221</td>\n",
       "      <td>0.882959</td>\n",
       "      <td>0.855482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.868056</td>\n",
       "      <td>0.878808</td>\n",
       "      <td>0.857305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.867477</td>\n",
       "      <td>0.876123</td>\n",
       "      <td>0.858832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.867169</td>\n",
       "      <td>0.873437</td>\n",
       "      <td>0.860902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.866997</td>\n",
       "      <td>0.872156</td>\n",
       "      <td>0.861838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.866843</td>\n",
       "      <td>0.871749</td>\n",
       "      <td>0.861936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.866794</td>\n",
       "      <td>0.872686</td>\n",
       "      <td>0.860902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.866720</td>\n",
       "      <td>0.870665</td>\n",
       "      <td>0.862774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.866603</td>\n",
       "      <td>0.878759</td>\n",
       "      <td>0.854447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.866498</td>\n",
       "      <td>0.871946</td>\n",
       "      <td>0.861050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.866467</td>\n",
       "      <td>0.873560</td>\n",
       "      <td>0.859374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.866381</td>\n",
       "      <td>0.870924</td>\n",
       "      <td>0.861838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.866319</td>\n",
       "      <td>0.874644</td>\n",
       "      <td>0.857995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.866110</td>\n",
       "      <td>0.876049</td>\n",
       "      <td>0.856171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.866098</td>\n",
       "      <td>0.874250</td>\n",
       "      <td>0.857945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.866011</td>\n",
       "      <td>0.870875</td>\n",
       "      <td>0.861148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.865846</td>\n",
       "      <td>0.921542</td>\n",
       "      <td>0.810150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.865716</td>\n",
       "      <td>0.893147</td>\n",
       "      <td>0.838285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.865568</td>\n",
       "      <td>0.881567</td>\n",
       "      <td>0.849569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.647143</td>\n",
       "      <td>0.894988</td>\n",
       "      <td>0.399297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.597016</td>\n",
       "      <td>0.756015</td>\n",
       "      <td>0.438017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.584095</td>\n",
       "      <td>0.707910</td>\n",
       "      <td>0.460280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.579399</td>\n",
       "      <td>0.680796</td>\n",
       "      <td>0.478002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.579230</td>\n",
       "      <td>0.643385</td>\n",
       "      <td>0.515075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.578725</td>\n",
       "      <td>0.629346</td>\n",
       "      <td>0.528105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.577987</td>\n",
       "      <td>0.638777</td>\n",
       "      <td>0.517196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.577191</td>\n",
       "      <td>0.651373</td>\n",
       "      <td>0.503008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.573658</td>\n",
       "      <td>0.632316</td>\n",
       "      <td>0.515000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.567265</td>\n",
       "      <td>0.667060</td>\n",
       "      <td>0.467470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.559821</td>\n",
       "      <td>0.617159</td>\n",
       "      <td>0.502483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.559644</td>\n",
       "      <td>0.615094</td>\n",
       "      <td>0.504193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.556577</td>\n",
       "      <td>0.607869</td>\n",
       "      <td>0.505285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.553951</td>\n",
       "      <td>0.620119</td>\n",
       "      <td>0.487782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.546818</td>\n",
       "      <td>0.618038</td>\n",
       "      <td>0.475599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.545781</td>\n",
       "      <td>0.640023</td>\n",
       "      <td>0.451538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.543556</td>\n",
       "      <td>0.625251</td>\n",
       "      <td>0.461861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.531890</td>\n",
       "      <td>0.637841</td>\n",
       "      <td>0.425938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.526475</td>\n",
       "      <td>0.676723</td>\n",
       "      <td>0.376227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.518323</td>\n",
       "      <td>0.720403</td>\n",
       "      <td>0.316242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.512926</td>\n",
       "      <td>0.713970</td>\n",
       "      <td>0.311881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.345115</td>\n",
       "      <td>0.446242</td>\n",
       "      <td>0.243989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.287867</td>\n",
       "      <td>0.346950</td>\n",
       "      <td>0.228784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.252104</td>\n",
       "      <td>0.296640</td>\n",
       "      <td>0.207567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.235129</td>\n",
       "      <td>0.275420</td>\n",
       "      <td>0.194837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.222309</td>\n",
       "      <td>0.255084</td>\n",
       "      <td>0.189533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.211124</td>\n",
       "      <td>0.238727</td>\n",
       "      <td>0.183522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.202990</td>\n",
       "      <td>0.227056</td>\n",
       "      <td>0.178925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.193133</td>\n",
       "      <td>0.216180</td>\n",
       "      <td>0.170085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.192916</td>\n",
       "      <td>0.265252</td>\n",
       "      <td>0.120580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.187651</td>\n",
       "      <td>0.206278</td>\n",
       "      <td>0.169024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.183675</td>\n",
       "      <td>0.236163</td>\n",
       "      <td>0.131188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.180447</td>\n",
       "      <td>0.221574</td>\n",
       "      <td>0.139321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.175452</td>\n",
       "      <td>0.208753</td>\n",
       "      <td>0.142150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.172445</td>\n",
       "      <td>0.197082</td>\n",
       "      <td>0.147808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.168688</td>\n",
       "      <td>0.200177</td>\n",
       "      <td>0.137199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.164930</td>\n",
       "      <td>0.184881</td>\n",
       "      <td>0.144979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.160730</td>\n",
       "      <td>0.175774</td>\n",
       "      <td>0.145686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.160598</td>\n",
       "      <td>0.182935</td>\n",
       "      <td>0.138260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.158652</td>\n",
       "      <td>0.174447</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         stat     valor                    \n",
       "                         list      mean       max       min\n",
       "2  accuracy   [treino, teste]  0.872738  0.893295  0.852180\n",
       "4  accuracy   [treino, teste]  0.869221  0.882959  0.855482\n",
       "6  accuracy   [treino, teste]  0.868056  0.878808  0.857305\n",
       "8  accuracy   [treino, teste]  0.867477  0.876123  0.858832\n",
       "12 accuracy   [treino, teste]  0.867169  0.873437  0.860902\n",
       "14 accuracy   [treino, teste]  0.866997  0.872156  0.861838\n",
       "16 accuracy   [treino, teste]  0.866843  0.871749  0.861936\n",
       "15 accuracy   [treino, teste]  0.866794  0.872686  0.860902\n",
       "20 accuracy   [treino, teste]  0.866720  0.870665  0.862774\n",
       "7  accuracy   [treino, teste]  0.866603  0.878759  0.854447\n",
       "17 accuracy   [treino, teste]  0.866498  0.871946  0.861050\n",
       "13 accuracy   [treino, teste]  0.866467  0.873560  0.859374\n",
       "18 accuracy   [treino, teste]  0.866381  0.870924  0.861838\n",
       "10 accuracy   [treino, teste]  0.866319  0.874644  0.857995\n",
       "9  accuracy   [treino, teste]  0.866110  0.876049  0.856171\n",
       "11 accuracy   [treino, teste]  0.866098  0.874250  0.857945\n",
       "19 accuracy   [treino, teste]  0.866011  0.870875  0.861148\n",
       "1  accuracy   [treino, teste]  0.865846  0.921542  0.810150\n",
       "3  accuracy   [treino, teste]  0.865716  0.893147  0.838285\n",
       "5  accuracy   [treino, teste]  0.865568  0.881567  0.849569\n",
       "2  precision  [treino, teste]  0.647143  0.894988  0.399297\n",
       "4  precision  [treino, teste]  0.597016  0.756015  0.438017\n",
       "6  precision  [treino, teste]  0.584095  0.707910  0.460280\n",
       "8  precision  [treino, teste]  0.579399  0.680796  0.478002\n",
       "14 precision  [treino, teste]  0.579230  0.643385  0.515075\n",
       "20 precision  [treino, teste]  0.578725  0.629346  0.528105\n",
       "16 precision  [treino, teste]  0.577987  0.638777  0.517196\n",
       "12 precision  [treino, teste]  0.577191  0.651373  0.503008\n",
       "18 precision  [treino, teste]  0.573658  0.632316  0.515000\n",
       "10 precision  [treino, teste]  0.567265  0.667060  0.467470\n",
       "15 precision  [treino, teste]  0.559821  0.617159  0.502483\n",
       "17 precision  [treino, teste]  0.559644  0.615094  0.504193\n",
       "19 precision  [treino, teste]  0.556577  0.607869  0.505285\n",
       "13 precision  [treino, teste]  0.553951  0.620119  0.487782\n",
       "11 precision  [treino, teste]  0.546818  0.618038  0.475599\n",
       "7  precision  [treino, teste]  0.545781  0.640023  0.451538\n",
       "9  precision  [treino, teste]  0.543556  0.625251  0.461861\n",
       "5  precision  [treino, teste]  0.531890  0.637841  0.425938\n",
       "3  precision  [treino, teste]  0.526475  0.676723  0.376227\n",
       "1  precision  [treino, teste]  0.518323  0.720403  0.316242\n",
       "   recall     [treino, teste]  0.512926  0.713970  0.311881\n",
       "3  recall     [treino, teste]  0.345115  0.446242  0.243989\n",
       "5  recall     [treino, teste]  0.287867  0.346950  0.228784\n",
       "7  recall     [treino, teste]  0.252104  0.296640  0.207567\n",
       "9  recall     [treino, teste]  0.235129  0.275420  0.194837\n",
       "11 recall     [treino, teste]  0.222309  0.255084  0.189533\n",
       "13 recall     [treino, teste]  0.211124  0.238727  0.183522\n",
       "15 recall     [treino, teste]  0.202990  0.227056  0.178925\n",
       "17 recall     [treino, teste]  0.193133  0.216180  0.170085\n",
       "2  recall     [treino, teste]  0.192916  0.265252  0.120580\n",
       "19 recall     [treino, teste]  0.187651  0.206278  0.169024\n",
       "4  recall     [treino, teste]  0.183675  0.236163  0.131188\n",
       "6  recall     [treino, teste]  0.180447  0.221574  0.139321\n",
       "8  recall     [treino, teste]  0.175452  0.208753  0.142150\n",
       "12 recall     [treino, teste]  0.172445  0.197082  0.147808\n",
       "10 recall     [treino, teste]  0.168688  0.200177  0.137199\n",
       "14 recall     [treino, teste]  0.164930  0.184881  0.144979\n",
       "18 recall     [treino, teste]  0.160730  0.175774  0.145686\n",
       "16 recall     [treino, teste]  0.160598  0.182935  0.138260\n",
       "20 recall     [treino, teste]  0.158652  0.174447  0.142857"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricas_modelos = pd.DataFrame().from_records(metricas_modelos)\n",
    "\n",
    "# Seleção dos melhores modelos com melhor K por Recall\n",
    "modelos = metricas_modelos.groupby(['K', 'metrica']).agg({'stat': list, 'valor': ['mean','max', 'min']})\n",
    "melhores_modelos = modelos.sort_values(\n",
    "    by=['metrica', ('valor', 'mean'),('valor', 'max'), ('valor', 'min'), 'K'],\n",
    "    key=lambda x: (~x.str.contains('recall', case=False, na=False)) if x.name == 'metrica' else x, \n",
    "    ascending=[True,False,False,False, False])\n",
    "idx_melhores_k_recall = melhores_modelos.index[0:20]\n",
    "melhores_modelos_k = []\n",
    "for k, _ in idx_melhores_k_recall:\n",
    "    for metrica in ['accuracy','precision', 'recall']:\n",
    "        melhores_modelos_k.append(melhores_modelos.loc[(k,metrica)])\n",
    "\n",
    "melhores_modelos_k = pd.DataFrame(melhores_modelos_k)\n",
    "melhores_modelos_k.sort_values(\n",
    "    by=[('valor', 'mean'),('valor', 'max'), ('valor', 'min')], \n",
    "    ascending=[False,False, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b126486d",
   "metadata": {},
   "source": [
    "### Analise dos resultados de 20 treinamentos de melhor Recall\n",
    "- Primeiramente nota-se que por causa do desbalanceamento de classes e underfitting nos modelos, com excessão de k = 1. Isso é visivel pelos indices accuracy dando quase a mesma porcentagem de casos com diabetes e recall de testes proximo a 25% para os dois melhores K's 1 e 3, o que significa que o modelo está basicamente escolhendo a classe, sem diabetes, para resposta de viés dominante. Já o acurácia indica que esse viés segue a proporção de casos com e sem diabetes.\n",
    "- A precisão indica que os dados de treino tem um bom retorno, mas os de teste parecem ser divergente do padrão.\n",
    "- Por enquanto é inconclusivo o melhor k, mas temos as 2 melhores opções do momento que é o k = 1 e k = 3.\n",
    "- O melhor k será melhor identificado na análise com kFolds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9d9404",
   "metadata": {},
   "source": [
    "### 3. Validação Cruzada e comparação entre modelos.\n",
    "- A validação cruzada permite uma comparação mais robusta entre os modelos, pois possibilita gerar modelos com dados de treinamento diferentes, pois permite que diferentes estatísticas possam ser geradas para a análise dos hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ec37b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josem\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8605639528437858\n",
      "0.1394360471562142\n",
      "-0.1620286867645797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josem\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.859701639626988\n",
      "0.14029836037301205\n",
      "-0.1631942454290134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josem\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\josem\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8604917588509202\n",
      "0.1395082411490798\n",
      "-0.1621261792621651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josem\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8599497400773609\n",
      "0.14005025992263914\n",
      "-0.1628586571931987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josem\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\josem\\miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8599866959028308\n",
      "0.1400133040971692\n",
      "-0.16280868618575584\n"
     ]
    }
   ],
   "source": [
    "metricas_dict = {\n",
    "    'accuracy': accuracy_score,\n",
    "    'precision': precision_score,\n",
    "    'recall': recall_score,\n",
    "    'f1_score': f1_score,\n",
    "    'r2_score':r2_score,\n",
    "    'mean_absolute_error': mean_absolute_error\n",
    "}\n",
    "metricas_modelos_fold = []\n",
    "\n",
    "kfolds = 5\n",
    "idx_fold = 0\n",
    "skf = StratifiedKFold(n_splits=kfolds, shuffle=True, random_state=7)\n",
    "for idx_treino, idx_teste in skf.split(X_selecionado, y_reduzido):\n",
    "    X_treino, X_teste = X_selecionado.iloc[idx_treino], X_selecionado.iloc[idx_teste]\n",
    "    y_treino, y_teste = y.iloc[idx_treino].values.ravel(), y.iloc[idx_teste].values.ravel()\n",
    "\n",
    "    normalizador1 = StandardScaler()\n",
    "    features_treino_normalizado = normalizador1.fit_transform(X_treino[features_to_normalize])\n",
    "    features_treino_normalizado = pd.DataFrame(features_treino_normalizado, columns=normalizador1.get_feature_names_out(), index=X_treino.index)\n",
    "    X_treino_normalizado = pd.concat([X_treino.drop(features_to_normalize, axis=1), features_treino_normalizado], axis=1)\n",
    "\n",
    "    normalizador2 = StandardScaler()\n",
    "    features_teste_normalizado = normalizador2.fit_transform(X_teste[features_to_normalize])\n",
    "    features_teste_normalizado = pd.DataFrame(features_teste_normalizado, columns=normalizador2.get_feature_names_out(), index=X_teste.index)\n",
    "    X_teste_normalizado = pd.concat([X_teste.drop(features_to_normalize, axis=1), features_teste_normalizado], axis=1)\n",
    "\n",
    "    Ks = [k for k in range(1,19,1)]\n",
    "    for K in Ks:\n",
    "        modelo_KNN = KNeighborsClassifier(n_neighbors=K)\n",
    "        modelo_KNN.fit(X_treino_normalizado, y_treino)\n",
    "\n",
    "        for metrica in ['accuracy', 'precision', 'recall', 'f1_score']:\n",
    "            metrica_avaliada_treino = metricas_dict[metrica](y_treino, modelo_KNN.predict(X_treino_normalizado))\n",
    "            metrica_avaliada_teste = metricas_dict[metrica](y_teste, modelo_KNN.predict(X_teste_normalizado))\n",
    "            metricas_modelos_fold.append({'modelo': f\"K-{K}\", 'fold': idx_fold, 'stat' : 'treino', 'metrica': metrica , 'valor': metrica_avaliada_treino})\n",
    "            metricas_modelos_fold.append({'modelo': f\"K-{K}\", 'fold': idx_fold, 'stat' : 'teste', 'metrica': metrica, 'valor': metrica_avaliada_teste})\n",
    "    \n",
    "    modelo_LGR = LogisticRegression(random_state=7, max_iter=500)\n",
    "    modelo_LGR.fit(X_treino_normalizado, y_treino)\n",
    "    for metrica in ['accuracy','mean_absolute_error','r2_score']:\n",
    "        metrica_avaliada_treino = metricas_dict[metrica](y_treino, modelo_LGR.predict(X_treino_normalizado))\n",
    "        print(metrica_avaliada_treino)\n",
    "        metrica_avaliada_teste = metricas_dict[metrica](y_teste, modelo_LGR.predict(X_teste_normalizado))\n",
    "        metricas_modelos_fold.append({'modelo': 'LGR', 'fold': idx_fold, 'stat' : 'treino', 'metrica': metrica , 'valor': metrica_avaliada_treino})\n",
    "        metricas_modelos_fold.append({'modelo': 'LGR', 'fold': idx_fold, 'stat' : 'teste', 'metrica': metrica, 'valor': metrica_avaliada_teste})\n",
    "        modelo_LGR.predict\n",
    "    idx_fold += 1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6b543793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>modelo</th>\n",
       "      <th>fold</th>\n",
       "      <th>metrica</th>\n",
       "      <th>stat</th>\n",
       "      <th colspan=\"3\" halign=\"left\">valor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>list</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K-1</td>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.340367</td>\n",
       "      <td>0.540170</td>\n",
       "      <td>0.140564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-1</td>\n",
       "      <td>3</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.338266</td>\n",
       "      <td>0.527399</td>\n",
       "      <td>0.149132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-1</td>\n",
       "      <td>4</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.336224</td>\n",
       "      <td>0.526658</td>\n",
       "      <td>0.145789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-1</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.336181</td>\n",
       "      <td>0.535982</td>\n",
       "      <td>0.136379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-1</td>\n",
       "      <td>0</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.330524</td>\n",
       "      <td>0.524605</td>\n",
       "      <td>0.136443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-3</td>\n",
       "      <td>0</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.123054</td>\n",
       "      <td>0.186589</td>\n",
       "      <td>0.059520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K-3</td>\n",
       "      <td>4</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.122710</td>\n",
       "      <td>0.189865</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K-3</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.119758</td>\n",
       "      <td>0.187196</td>\n",
       "      <td>0.052319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>K-3</td>\n",
       "      <td>3</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.119197</td>\n",
       "      <td>0.182426</td>\n",
       "      <td>0.055969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>K-3</td>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.116531</td>\n",
       "      <td>0.185969</td>\n",
       "      <td>0.047092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>K-2</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.056331</td>\n",
       "      <td>0.091038</td>\n",
       "      <td>0.021625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>K-2</td>\n",
       "      <td>3</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.054565</td>\n",
       "      <td>0.087167</td>\n",
       "      <td>0.021962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>K-2</td>\n",
       "      <td>0</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.052480</td>\n",
       "      <td>0.087905</td>\n",
       "      <td>0.017055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>K-2</td>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.051967</td>\n",
       "      <td>0.088594</td>\n",
       "      <td>0.015341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>K-2</td>\n",
       "      <td>4</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.050193</td>\n",
       "      <td>0.084462</td>\n",
       "      <td>0.015924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>K-5</td>\n",
       "      <td>2</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.049510</td>\n",
       "      <td>0.073907</td>\n",
       "      <td>0.025113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>K-5</td>\n",
       "      <td>3</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.048443</td>\n",
       "      <td>0.077403</td>\n",
       "      <td>0.019483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>K-5</td>\n",
       "      <td>4</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.047740</td>\n",
       "      <td>0.075664</td>\n",
       "      <td>0.019816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>K-5</td>\n",
       "      <td>1</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.047130</td>\n",
       "      <td>0.074282</td>\n",
       "      <td>0.019979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>K-5</td>\n",
       "      <td>0</td>\n",
       "      <td>recall</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>0.073593</td>\n",
       "      <td>0.020536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>K-2</td>\n",
       "      <td>3</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.358573</td>\n",
       "      <td>0.577506</td>\n",
       "      <td>0.139640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>K-2</td>\n",
       "      <td>4</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.354285</td>\n",
       "      <td>0.590769</td>\n",
       "      <td>0.117801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>K-2</td>\n",
       "      <td>0</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.354000</td>\n",
       "      <td>0.567598</td>\n",
       "      <td>0.140401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>K-2</td>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.350973</td>\n",
       "      <td>0.582486</td>\n",
       "      <td>0.119461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>K-2</td>\n",
       "      <td>1</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.338976</td>\n",
       "      <td>0.569092</td>\n",
       "      <td>0.108861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>K-1</td>\n",
       "      <td>4</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.317666</td>\n",
       "      <td>0.497631</td>\n",
       "      <td>0.137701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>K-1</td>\n",
       "      <td>0</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.316621</td>\n",
       "      <td>0.494627</td>\n",
       "      <td>0.138614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>K-1</td>\n",
       "      <td>1</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.314593</td>\n",
       "      <td>0.492475</td>\n",
       "      <td>0.136711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>K-1</td>\n",
       "      <td>3</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.314356</td>\n",
       "      <td>0.491355</td>\n",
       "      <td>0.137357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>K-1</td>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.313173</td>\n",
       "      <td>0.490347</td>\n",
       "      <td>0.136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>K-5</td>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.304400</td>\n",
       "      <td>0.474221</td>\n",
       "      <td>0.134579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>K-3</td>\n",
       "      <td>2</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.302002</td>\n",
       "      <td>0.467888</td>\n",
       "      <td>0.136116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>K-3</td>\n",
       "      <td>0</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.299815</td>\n",
       "      <td>0.432964</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>K-5</td>\n",
       "      <td>4</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.299223</td>\n",
       "      <td>0.471750</td>\n",
       "      <td>0.126697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>K-5</td>\n",
       "      <td>1</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.298779</td>\n",
       "      <td>0.474481</td>\n",
       "      <td>0.123077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>K-5</td>\n",
       "      <td>3</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.294378</td>\n",
       "      <td>0.460251</td>\n",
       "      <td>0.128505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>K-3</td>\n",
       "      <td>3</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.294171</td>\n",
       "      <td>0.449502</td>\n",
       "      <td>0.138840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>K-3</td>\n",
       "      <td>1</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.294149</td>\n",
       "      <td>0.461740</td>\n",
       "      <td>0.126558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>K-5</td>\n",
       "      <td>0</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.293661</td>\n",
       "      <td>0.436812</td>\n",
       "      <td>0.150510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>K-3</td>\n",
       "      <td>4</td>\n",
       "      <td>precision</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.291724</td>\n",
       "      <td>0.453266</td>\n",
       "      <td>0.130182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>K-2</td>\n",
       "      <td>4</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.854990</td>\n",
       "      <td>0.863621</td>\n",
       "      <td>0.846359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>K-2</td>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.854777</td>\n",
       "      <td>0.863483</td>\n",
       "      <td>0.846070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>K-2</td>\n",
       "      <td>1</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.854691</td>\n",
       "      <td>0.862720</td>\n",
       "      <td>0.846662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>K-2</td>\n",
       "      <td>3</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.854177</td>\n",
       "      <td>0.863226</td>\n",
       "      <td>0.845127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>K-5</td>\n",
       "      <td>1</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.851784</td>\n",
       "      <td>0.858581</td>\n",
       "      <td>0.844986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>K-2</td>\n",
       "      <td>2</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.851676</td>\n",
       "      <td>0.864089</td>\n",
       "      <td>0.839263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>K-5</td>\n",
       "      <td>3</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.851651</td>\n",
       "      <td>0.858077</td>\n",
       "      <td>0.845225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>K-5</td>\n",
       "      <td>4</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.851602</td>\n",
       "      <td>0.858718</td>\n",
       "      <td>0.844486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>K-5</td>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.851266</td>\n",
       "      <td>0.857595</td>\n",
       "      <td>0.844937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>K-5</td>\n",
       "      <td>2</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.849415</td>\n",
       "      <td>0.859371</td>\n",
       "      <td>0.839460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>K-3</td>\n",
       "      <td>1</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.839441</td>\n",
       "      <td>0.855378</td>\n",
       "      <td>0.823503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>K-3</td>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.838621</td>\n",
       "      <td>0.852507</td>\n",
       "      <td>0.824735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>K-3</td>\n",
       "      <td>2</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.838057</td>\n",
       "      <td>0.856907</td>\n",
       "      <td>0.819208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>K-3</td>\n",
       "      <td>3</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.837300</td>\n",
       "      <td>0.854209</td>\n",
       "      <td>0.820390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>K-3</td>\n",
       "      <td>4</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.835649</td>\n",
       "      <td>0.854505</td>\n",
       "      <td>0.816793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>K-1</td>\n",
       "      <td>0</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.808349</td>\n",
       "      <td>0.858975</td>\n",
       "      <td>0.757724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>K-1</td>\n",
       "      <td>1</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.808047</td>\n",
       "      <td>0.857386</td>\n",
       "      <td>0.758709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>K-1</td>\n",
       "      <td>4</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.806601</td>\n",
       "      <td>0.859285</td>\n",
       "      <td>0.753917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>K-1</td>\n",
       "      <td>2</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.806570</td>\n",
       "      <td>0.857548</td>\n",
       "      <td>0.755593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>K-1</td>\n",
       "      <td>3</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.804353</td>\n",
       "      <td>0.857351</td>\n",
       "      <td>0.751355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   modelo fold    metrica             stat     valor                    \n",
       "                                      list      mean       max       min\n",
       "0     K-1    1     recall  [treino, teste]  0.340367  0.540170  0.140564\n",
       "1     K-1    3     recall  [treino, teste]  0.338266  0.527399  0.149132\n",
       "2     K-1    4     recall  [treino, teste]  0.336224  0.526658  0.145789\n",
       "3     K-1    2     recall  [treino, teste]  0.336181  0.535982  0.136379\n",
       "4     K-1    0     recall  [treino, teste]  0.330524  0.524605  0.136443\n",
       "5     K-3    0     recall  [treino, teste]  0.123054  0.186589  0.059520\n",
       "6     K-3    4     recall  [treino, teste]  0.122710  0.189865  0.055556\n",
       "7     K-3    2     recall  [treino, teste]  0.119758  0.187196  0.052319\n",
       "8     K-3    3     recall  [treino, teste]  0.119197  0.182426  0.055969\n",
       "9     K-3    1     recall  [treino, teste]  0.116531  0.185969  0.047092\n",
       "10    K-2    2     recall  [treino, teste]  0.056331  0.091038  0.021625\n",
       "11    K-2    3     recall  [treino, teste]  0.054565  0.087167  0.021962\n",
       "12    K-2    0     recall  [treino, teste]  0.052480  0.087905  0.017055\n",
       "13    K-2    1     recall  [treino, teste]  0.051967  0.088594  0.015341\n",
       "14    K-2    4     recall  [treino, teste]  0.050193  0.084462  0.015924\n",
       "15    K-5    2     recall  [treino, teste]  0.049510  0.073907  0.025113\n",
       "16    K-5    3     recall  [treino, teste]  0.048443  0.077403  0.019483\n",
       "17    K-5    4     recall  [treino, teste]  0.047740  0.075664  0.019816\n",
       "18    K-5    1     recall  [treino, teste]  0.047130  0.074282  0.019979\n",
       "19    K-5    0     recall  [treino, teste]  0.047065  0.073593  0.020536\n",
       "20    K-2    3  precision  [treino, teste]  0.358573  0.577506  0.139640\n",
       "21    K-2    4  precision  [treino, teste]  0.354285  0.590769  0.117801\n",
       "22    K-2    0  precision  [treino, teste]  0.354000  0.567598  0.140401\n",
       "23    K-2    2  precision  [treino, teste]  0.350973  0.582486  0.119461\n",
       "24    K-2    1  precision  [treino, teste]  0.338976  0.569092  0.108861\n",
       "25    K-1    4  precision  [treino, teste]  0.317666  0.497631  0.137701\n",
       "26    K-1    0  precision  [treino, teste]  0.316621  0.494627  0.138614\n",
       "27    K-1    1  precision  [treino, teste]  0.314593  0.492475  0.136711\n",
       "28    K-1    3  precision  [treino, teste]  0.314356  0.491355  0.137357\n",
       "29    K-1    2  precision  [treino, teste]  0.313173  0.490347  0.136000\n",
       "30    K-5    2  precision  [treino, teste]  0.304400  0.474221  0.134579\n",
       "31    K-3    2  precision  [treino, teste]  0.302002  0.467888  0.136116\n",
       "32    K-3    0  precision  [treino, teste]  0.299815  0.432964  0.166667\n",
       "33    K-5    4  precision  [treino, teste]  0.299223  0.471750  0.126697\n",
       "34    K-5    1  precision  [treino, teste]  0.298779  0.474481  0.123077\n",
       "35    K-5    3  precision  [treino, teste]  0.294378  0.460251  0.128505\n",
       "36    K-3    3  precision  [treino, teste]  0.294171  0.449502  0.138840\n",
       "37    K-3    1  precision  [treino, teste]  0.294149  0.461740  0.126558\n",
       "38    K-5    0  precision  [treino, teste]  0.293661  0.436812  0.150510\n",
       "39    K-3    4  precision  [treino, teste]  0.291724  0.453266  0.130182\n",
       "40    K-2    4   accuracy  [treino, teste]  0.854990  0.863621  0.846359\n",
       "41    K-2    0   accuracy  [treino, teste]  0.854777  0.863483  0.846070\n",
       "42    K-2    1   accuracy  [treino, teste]  0.854691  0.862720  0.846662\n",
       "43    K-2    3   accuracy  [treino, teste]  0.854177  0.863226  0.845127\n",
       "44    K-5    1   accuracy  [treino, teste]  0.851784  0.858581  0.844986\n",
       "45    K-2    2   accuracy  [treino, teste]  0.851676  0.864089  0.839263\n",
       "46    K-5    3   accuracy  [treino, teste]  0.851651  0.858077  0.845225\n",
       "47    K-5    4   accuracy  [treino, teste]  0.851602  0.858718  0.844486\n",
       "48    K-5    0   accuracy  [treino, teste]  0.851266  0.857595  0.844937\n",
       "49    K-5    2   accuracy  [treino, teste]  0.849415  0.859371  0.839460\n",
       "50    K-3    1   accuracy  [treino, teste]  0.839441  0.855378  0.823503\n",
       "51    K-3    0   accuracy  [treino, teste]  0.838621  0.852507  0.824735\n",
       "52    K-3    2   accuracy  [treino, teste]  0.838057  0.856907  0.819208\n",
       "53    K-3    3   accuracy  [treino, teste]  0.837300  0.854209  0.820390\n",
       "54    K-3    4   accuracy  [treino, teste]  0.835649  0.854505  0.816793\n",
       "55    K-1    0   accuracy  [treino, teste]  0.808349  0.858975  0.757724\n",
       "56    K-1    1   accuracy  [treino, teste]  0.808047  0.857386  0.758709\n",
       "57    K-1    4   accuracy  [treino, teste]  0.806601  0.859285  0.753917\n",
       "58    K-1    2   accuracy  [treino, teste]  0.806570  0.857548  0.755593\n",
       "59    K-1    3   accuracy  [treino, teste]  0.804353  0.857351  0.751355"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricas_modelos_fold = pd.DataFrame().from_records(metricas_modelos_fold)\n",
    "\n",
    "# Seleção dos melhores modelos com melhor K por Recall\n",
    "modelos = metricas_modelos_fold.groupby(['modelo','fold', 'metrica']).agg({'stat': list, 'valor': ['mean','max', 'min']})\n",
    "melhores_modelos = modelos.sort_values(\n",
    "    by=['metrica',('valor', 'mean'),('valor','max'), ('valor', 'min')],\n",
    "    key=lambda x: (~x.str.contains('recall', case=False, na=False)) if x.name == 'metrica' else x, \n",
    "    ascending=[True,False, False,False])\n",
    "idx_melhores_modelos_recall = melhores_modelos.index[0:20]\n",
    "melhores_modelos_final = []\n",
    "for modelo, fold, _ in idx_melhores_modelos_recall:\n",
    "    for metrica in ['accuracy','precision', 'recall']:\n",
    "        melhores_modelos_final.append(melhores_modelos.loc[modelo, fold, metrica])\n",
    "\n",
    "\n",
    "melhores_modelos_final = pd.DataFrame(melhores_modelos_final)\n",
    "melhores_modelos_final.index.names=['modelo','fold', 'metrica']\n",
    "melhores_modelos_final = melhores_modelos_final.reset_index(level=['modelo','fold', 'metrica'])\n",
    "melhores_modelos_final.sort_values(\n",
    "    by=['metrica', ('valor', 'mean'), ('valor', 'min')],\n",
    "    ascending=[False, False,False], ignore_index= True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebef93c",
   "metadata": {},
   "source": [
    "### Resultado KNN 5 folds\n",
    "- Com a inclusão da validação cruzada vemos que os indices das métricas pioram, ou seja, é mais confiável que não haja uma correlação direta entre as features e o target, gerando um underfitting no modelo de previsão.\n",
    "- Os indices indicam que não há um padrão KNN reconhecível nos modelos, ou seja, não a separação na região das features que separe bem as classes a serem identificadas.\n",
    "- De qualquer forma, apesar dos péssimos índices dos modelos, o modelo k = 1, com media de acurácia e recall de treino e teste de 83% e 42% respectivamente , foi o que obteve maior recall, característica visada em diagnósticos médicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93e96bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>stat</th>\n",
       "      <th colspan=\"2\" halign=\"left\">valor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>list</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th>metrica</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>r2_score</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>-0.161719</td>\n",
       "      <td>-0.163194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>r2_score</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>-0.162220</td>\n",
       "      <td>-0.162859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>r2_score</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>-0.162295</td>\n",
       "      <td>-0.162809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>r2_score</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>-0.163321</td>\n",
       "      <td>-0.164515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>r2_score</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>-0.163468</td>\n",
       "      <td>-0.164906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.860794</td>\n",
       "      <td>0.859702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.860422</td>\n",
       "      <td>0.859950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.860367</td>\n",
       "      <td>0.859987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.859609</td>\n",
       "      <td>0.858727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.859501</td>\n",
       "      <td>0.858438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.140499</td>\n",
       "      <td>0.139436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.140391</td>\n",
       "      <td>0.139508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.139633</td>\n",
       "      <td>0.139253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.139578</td>\n",
       "      <td>0.139105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.139206</td>\n",
       "      <td>0.138113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     stat     valor          \n",
       "                                     list      mean       min\n",
       "fold metrica                                                 \n",
       "1    r2_score             [treino, teste] -0.161719 -0.163194\n",
       "3    r2_score             [treino, teste] -0.162220 -0.162859\n",
       "4    r2_score             [treino, teste] -0.162295 -0.162809\n",
       "2    r2_score             [treino, teste] -0.163321 -0.164515\n",
       "0    r2_score             [treino, teste] -0.163468 -0.164906\n",
       "1    accuracy             [treino, teste]  0.860794  0.859702\n",
       "3    accuracy             [treino, teste]  0.860422  0.859950\n",
       "4    accuracy             [treino, teste]  0.860367  0.859987\n",
       "2    accuracy             [treino, teste]  0.859609  0.858727\n",
       "0    accuracy             [treino, teste]  0.859501  0.858438\n",
       "     mean_absolute_error  [treino, teste]  0.140499  0.139436\n",
       "2    mean_absolute_error  [treino, teste]  0.140391  0.139508\n",
       "4    mean_absolute_error  [treino, teste]  0.139633  0.139253\n",
       "3    mean_absolute_error  [treino, teste]  0.139578  0.139105\n",
       "1    mean_absolute_error  [treino, teste]  0.139206  0.138113"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# melhor Regressão Logistica\n",
    "modelos = metricas_modelos_fold['modelo'] == 'LGR'\n",
    "modelos = metricas_modelos_fold.loc[modelos].groupby(['fold' ,'metrica']).agg({'stat': list, 'valor': ['mean', 'min']})\n",
    "melhores_modelos = modelos.sort_values(\n",
    "    by=['metrica',('valor', 'mean'), ('valor', 'min')],\n",
    "    key=lambda x: (~x.str.contains('r2_score', case=False, na=False)) if x.name == 'metrica' else x, \n",
    "    ascending=[True,False, False])\n",
    "melhores_modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ec7752",
   "metadata": {},
   "source": [
    "### Resultado Regressão Logística 5 folds\n",
    "- Já na Regressão Logística temos a acurácia e error medio absoluto dando a mesma proporção de casos de ausencia e presença de diabetes o que significa que o modelo está enviesado na classificação da regressão Logística, provavelmente resultando em um mesmo valor, sem diabetes, em todos oos casos.\n",
    "- O R² negativado mostra que o modelo gerado faz previsões piores que uma simples linha horizontal entre os dados (que representa a média dos dados), o que ocorre quando ao modelo não captura a tendência dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39723e1c",
   "metadata": {},
   "source": [
    "### Comparação dos Modelos KNN e Regressão Logística.\n",
    "- Considerando os dois modelos, KNN com k = 1 e fold = 1, e Regressão Logística que praticamente entrega o mesmo resultado entre os 5 modelos variando folds, temos que ambos os modelos são péssimos mas a regressão logística falhou totalmente em prever algum valor não enviesado. \n",
    "- O modelo KNN pelo menos teve um desempenho de 70% no treino apesar de errar quase todo o teste. Ficando uma disparidade média de 40% de previsão positiva entre valores positivos da doença contra praticamente 0% da regressão logística, apesar da acurácia de ambos darem proximo de 85% se dá pela relação de que quase todas as respostas foram enviesadas para target 0, sem diabetes, que especificamente no caso é de 86,07% dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0147ca",
   "metadata": {},
   "source": [
    "# Avaliação Final e Otimização do Desempenho Preditivo\n",
    "- Primeiramente balancearemos a classe majoritária para equilibrá-la a minoritária.\n",
    "- Então vamos revalidar as features mais relevantes escalando e as transformando no processo PCA.\n",
    "- Seguimos com o modelo grid para testar os hiperparâmetros e obter os scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f000381",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X,y], axis=1)\n",
    "# Separando as classes\n",
    "df_majoritario = X[X['Diabetes_binary'] == 0]\n",
    "df_minoritario = X[X['Diabetes_binary'] == 1]\n",
    "\n",
    "# Determinando o tamanho da classe minoritária\n",
    "tamanho_minoritario = len(df_minoritario)\n",
    "\n",
    "# Amostrar aleatoriamente a classe majoritária\n",
    "df_amostras_majoritario = df_majoritario.sample(n=tamanho_minoritario, random_state=7, replace=False)\n",
    "\n",
    "# Combinando as classes balanceadas\n",
    "df_balanceado = pd.concat([df_amostras_majoritario, df_minoritario], axis=0)\n",
    "\n",
    "# Embaralhando os dados\n",
    "df_balanceado = df_balanceado.sample(frac=1, random_state=7).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db3c40bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_balanceado['Diabetes_binary']\n",
    "scaler = MinMaxScaler()\n",
    "X_escalado_balanceado = scaler.fit_transform(df_balanceado.drop(columns=['Diabetes_binary']))\n",
    "n_features_data = []\n",
    "for n_features in [5,10,15]:\n",
    "    pca = PCA(n_components=n_features, random_state=7)\n",
    "    X_revisado = pca.fit_transform(X_escalado_balanceado)\n",
    "    X_revisado = pd.DataFrame(X_revisado, columns=pca.get_feature_names_out())\n",
    "    n_features_data.append(X_revisado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7630430",
   "metadata": {},
   "source": [
    "- Por questões de capacidade computacional, foi limitado o ajuste de de hiperparametros para o resultado ótimo depois de muitos testes de longa duração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06a5c6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelos = []\n",
    "estatisticas = []\n",
    "for X_pca in n_features_data:\n",
    "    knn = KNeighborsClassifier()\n",
    "    param_grid = {\"n_neighbors\": [33], \"weights\": ['uniform'], \"p\": [1,4]}\n",
    "    score_param = ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
    "    modelos_grid = GridSearchCV(knn, param_grid=param_grid, scoring=score_param,cv=5, refit=False)\n",
    "    modelos_grid.fit(X_pca, y.values.ravel())\n",
    "    estatisticas.append(pd.DataFrame().from_records(modelos_grid.cv_results_))\n",
    "    modelos.append(modelos_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598dd32c",
   "metadata": {},
   "source": [
    "- para cada Conjunto de PCAs foi escolhido o melhor modelo baseada na métrica recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d28ecb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.202843</td>\n",
       "      <td>0.311763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>2.85456</td>\n",
       "      <td>14.169136</td>\n",
       "      <td>20.489487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <td>0.723109</td>\n",
       "      <td>0.721609</td>\n",
       "      <td>0.720152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_f1</th>\n",
       "      <td>0.740091</td>\n",
       "      <td>0.737134</td>\n",
       "      <td>0.73493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_precision</th>\n",
       "      <td>0.697345</td>\n",
       "      <td>0.698218</td>\n",
       "      <td>0.698076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_recall</th>\n",
       "      <td>0.788434</td>\n",
       "      <td>0.780654</td>\n",
       "      <td>0.775901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_roc_auc</th>\n",
       "      <td>0.789168</td>\n",
       "      <td>0.786775</td>\n",
       "      <td>0.785719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_p</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_weights</th>\n",
       "      <td>uniform</td>\n",
       "      <td>uniform</td>\n",
       "      <td>uniform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'n_neighbors': 33, 'p': 4, 'weights': 'uniform'}</td>\n",
       "      <td>{'n_neighbors': 33, 'p': 4, 'weights': 'uniform'}</td>\n",
       "      <td>{'n_neighbors': 33, 'p': 1, 'weights': 'uniform'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_f1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_precision</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_recall</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_roc_auc</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <td>0.726572</td>\n",
       "      <td>0.726713</td>\n",
       "      <td>0.723955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_f1</th>\n",
       "      <td>0.74237</td>\n",
       "      <td>0.740845</td>\n",
       "      <td>0.738703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_precision</th>\n",
       "      <td>0.701865</td>\n",
       "      <td>0.704464</td>\n",
       "      <td>0.701284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_recall</th>\n",
       "      <td>0.787836</td>\n",
       "      <td>0.781188</td>\n",
       "      <td>0.780339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_roc_auc</th>\n",
       "      <td>0.790393</td>\n",
       "      <td>0.787907</td>\n",
       "      <td>0.787843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <td>0.716953</td>\n",
       "      <td>0.716104</td>\n",
       "      <td>0.714195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_f1</th>\n",
       "      <td>0.734932</td>\n",
       "      <td>0.732471</td>\n",
       "      <td>0.730006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_precision</th>\n",
       "      <td>0.690995</td>\n",
       "      <td>0.692502</td>\n",
       "      <td>0.691694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_recall</th>\n",
       "      <td>0.784835</td>\n",
       "      <td>0.777338</td>\n",
       "      <td>0.772811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_roc_auc</th>\n",
       "      <td>0.785702</td>\n",
       "      <td>0.783673</td>\n",
       "      <td>0.782249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_accuracy</th>\n",
       "      <td>0.721955</td>\n",
       "      <td>0.721743</td>\n",
       "      <td>0.718206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_f1</th>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.737803</td>\n",
       "      <td>0.732761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_precision</th>\n",
       "      <td>0.69549</td>\n",
       "      <td>0.697543</td>\n",
       "      <td>0.696773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_recall</th>\n",
       "      <td>0.789645</td>\n",
       "      <td>0.782996</td>\n",
       "      <td>0.772669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_roc_auc</th>\n",
       "      <td>0.788315</td>\n",
       "      <td>0.785472</td>\n",
       "      <td>0.783238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_accuracy</th>\n",
       "      <td>0.724926</td>\n",
       "      <td>0.720894</td>\n",
       "      <td>0.721531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_f1</th>\n",
       "      <td>0.740751</td>\n",
       "      <td>0.736054</td>\n",
       "      <td>0.735257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_precision</th>\n",
       "      <td>0.700454</td>\n",
       "      <td>0.698135</td>\n",
       "      <td>0.700718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_recall</th>\n",
       "      <td>0.785967</td>\n",
       "      <td>0.778328</td>\n",
       "      <td>0.773377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_roc_auc</th>\n",
       "      <td>0.789639</td>\n",
       "      <td>0.788553</td>\n",
       "      <td>0.786849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_accuracy</th>\n",
       "      <td>0.725138</td>\n",
       "      <td>0.722592</td>\n",
       "      <td>0.722875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_f1</th>\n",
       "      <td>0.742819</td>\n",
       "      <td>0.738498</td>\n",
       "      <td>0.737926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_precision</th>\n",
       "      <td>0.697923</td>\n",
       "      <td>0.698449</td>\n",
       "      <td>0.699911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_recall</th>\n",
       "      <td>0.793889</td>\n",
       "      <td>0.783421</td>\n",
       "      <td>0.780308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_roc_auc</th>\n",
       "      <td>0.791788</td>\n",
       "      <td>0.788272</td>\n",
       "      <td>0.788414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.002856</td>\n",
       "      <td>0.00566</td>\n",
       "      <td>0.006313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.114599</td>\n",
       "      <td>0.873434</td>\n",
       "      <td>3.743474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.003551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_f1</th>\n",
       "      <td>0.002827</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.003233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_precision</th>\n",
       "      <td>0.003852</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.003551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_recall</th>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.003619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_roc_auc</th>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       1  \\\n",
       "mean_fit_time                                                     0.1028   \n",
       "mean_score_time                                                  2.85456   \n",
       "mean_test_accuracy                                              0.723109   \n",
       "mean_test_f1                                                    0.740091   \n",
       "mean_test_precision                                             0.697345   \n",
       "mean_test_recall                                                0.788434   \n",
       "mean_test_roc_auc                                               0.789168   \n",
       "param_n_neighbors                                                     33   \n",
       "param_p                                                                4   \n",
       "param_weights                                                    uniform   \n",
       "params                 {'n_neighbors': 33, 'p': 4, 'weights': 'uniform'}   \n",
       "rank_test_accuracy                                                     1   \n",
       "rank_test_f1                                                           1   \n",
       "rank_test_precision                                                    1   \n",
       "rank_test_recall                                                       1   \n",
       "rank_test_roc_auc                                                      1   \n",
       "split0_test_accuracy                                            0.726572   \n",
       "split0_test_f1                                                   0.74237   \n",
       "split0_test_precision                                           0.701865   \n",
       "split0_test_recall                                              0.787836   \n",
       "split0_test_roc_auc                                             0.790393   \n",
       "split1_test_accuracy                                            0.716953   \n",
       "split1_test_f1                                                  0.734932   \n",
       "split1_test_precision                                           0.690995   \n",
       "split1_test_recall                                              0.784835   \n",
       "split1_test_roc_auc                                             0.785702   \n",
       "split2_test_accuracy                                            0.721955   \n",
       "split2_test_f1                                                  0.739583   \n",
       "split2_test_precision                                            0.69549   \n",
       "split2_test_recall                                              0.789645   \n",
       "split2_test_roc_auc                                             0.788315   \n",
       "split3_test_accuracy                                            0.724926   \n",
       "split3_test_f1                                                  0.740751   \n",
       "split3_test_precision                                           0.700454   \n",
       "split3_test_recall                                              0.785967   \n",
       "split3_test_roc_auc                                             0.789639   \n",
       "split4_test_accuracy                                            0.725138   \n",
       "split4_test_f1                                                  0.742819   \n",
       "split4_test_precision                                           0.697923   \n",
       "split4_test_recall                                              0.793889   \n",
       "split4_test_roc_auc                                             0.791788   \n",
       "std_fit_time                                                    0.002856   \n",
       "std_score_time                                                  0.114599   \n",
       "std_test_accuracy                                               0.003424   \n",
       "std_test_f1                                                     0.002827   \n",
       "std_test_precision                                              0.003852   \n",
       "std_test_recall                                                 0.003182   \n",
       "std_test_roc_auc                                                0.002065   \n",
       "\n",
       "                                                                       1  \\\n",
       "mean_fit_time                                                   0.202843   \n",
       "mean_score_time                                                14.169136   \n",
       "mean_test_accuracy                                              0.721609   \n",
       "mean_test_f1                                                    0.737134   \n",
       "mean_test_precision                                             0.698218   \n",
       "mean_test_recall                                                0.780654   \n",
       "mean_test_roc_auc                                               0.786775   \n",
       "param_n_neighbors                                                     33   \n",
       "param_p                                                                4   \n",
       "param_weights                                                    uniform   \n",
       "params                 {'n_neighbors': 33, 'p': 4, 'weights': 'uniform'}   \n",
       "rank_test_accuracy                                                     1   \n",
       "rank_test_f1                                                           1   \n",
       "rank_test_precision                                                    2   \n",
       "rank_test_recall                                                       1   \n",
       "rank_test_roc_auc                                                      1   \n",
       "split0_test_accuracy                                            0.726713   \n",
       "split0_test_f1                                                  0.740845   \n",
       "split0_test_precision                                           0.704464   \n",
       "split0_test_recall                                              0.781188   \n",
       "split0_test_roc_auc                                             0.787907   \n",
       "split1_test_accuracy                                            0.716104   \n",
       "split1_test_f1                                                  0.732471   \n",
       "split1_test_precision                                           0.692502   \n",
       "split1_test_recall                                              0.777338   \n",
       "split1_test_roc_auc                                             0.783673   \n",
       "split2_test_accuracy                                            0.721743   \n",
       "split2_test_f1                                                  0.737803   \n",
       "split2_test_precision                                           0.697543   \n",
       "split2_test_recall                                              0.782996   \n",
       "split2_test_roc_auc                                             0.785472   \n",
       "split3_test_accuracy                                            0.720894   \n",
       "split3_test_f1                                                  0.736054   \n",
       "split3_test_precision                                           0.698135   \n",
       "split3_test_recall                                              0.778328   \n",
       "split3_test_roc_auc                                             0.788553   \n",
       "split4_test_accuracy                                            0.722592   \n",
       "split4_test_f1                                                  0.738498   \n",
       "split4_test_precision                                           0.698449   \n",
       "split4_test_recall                                              0.783421   \n",
       "split4_test_roc_auc                                             0.788272   \n",
       "std_fit_time                                                     0.00566   \n",
       "std_score_time                                                  0.873434   \n",
       "std_test_accuracy                                               0.003401   \n",
       "std_test_f1                                                     0.002792   \n",
       "std_test_precision                                                0.0038   \n",
       "std_test_recall                                                 0.002443   \n",
       "std_test_roc_auc                                                0.001898   \n",
       "\n",
       "                                                                       0  \n",
       "mean_fit_time                                                   0.311763  \n",
       "mean_score_time                                                20.489487  \n",
       "mean_test_accuracy                                              0.720152  \n",
       "mean_test_f1                                                     0.73493  \n",
       "mean_test_precision                                             0.698076  \n",
       "mean_test_recall                                                0.775901  \n",
       "mean_test_roc_auc                                               0.785719  \n",
       "param_n_neighbors                                                     33  \n",
       "param_p                                                                1  \n",
       "param_weights                                                    uniform  \n",
       "params                 {'n_neighbors': 33, 'p': 1, 'weights': 'uniform'}  \n",
       "rank_test_accuracy                                                     1  \n",
       "rank_test_f1                                                           1  \n",
       "rank_test_precision                                                    2  \n",
       "rank_test_recall                                                       1  \n",
       "rank_test_roc_auc                                                      1  \n",
       "split0_test_accuracy                                            0.723955  \n",
       "split0_test_f1                                                  0.738703  \n",
       "split0_test_precision                                           0.701284  \n",
       "split0_test_recall                                              0.780339  \n",
       "split0_test_roc_auc                                             0.787843  \n",
       "split1_test_accuracy                                            0.714195  \n",
       "split1_test_f1                                                  0.730006  \n",
       "split1_test_precision                                           0.691694  \n",
       "split1_test_recall                                              0.772811  \n",
       "split1_test_roc_auc                                             0.782249  \n",
       "split2_test_accuracy                                            0.718206  \n",
       "split2_test_f1                                                  0.732761  \n",
       "split2_test_precision                                           0.696773  \n",
       "split2_test_recall                                              0.772669  \n",
       "split2_test_roc_auc                                             0.783238  \n",
       "split3_test_accuracy                                            0.721531  \n",
       "split3_test_f1                                                  0.735257  \n",
       "split3_test_precision                                           0.700718  \n",
       "split3_test_recall                                              0.773377  \n",
       "split3_test_roc_auc                                             0.786849  \n",
       "split4_test_accuracy                                            0.722875  \n",
       "split4_test_f1                                                  0.737926  \n",
       "split4_test_precision                                           0.699911  \n",
       "split4_test_recall                                              0.780308  \n",
       "split4_test_roc_auc                                             0.788414  \n",
       "std_fit_time                                                    0.006313  \n",
       "std_score_time                                                  3.743474  \n",
       "std_test_accuracy                                               0.003551  \n",
       "std_test_f1                                                     0.003233  \n",
       "std_test_precision                                              0.003551  \n",
       "std_test_recall                                                 0.003619  \n",
       "std_test_roc_auc                                                  0.0025  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Escolha do melhor modelo para cada conjunto de PCAs\n",
    "melhores_modelos = pd.DataFrame()\n",
    "for model in estatisticas:\n",
    "    melhores_modelos = pd.concat([melhores_modelos, model.iloc[model.sort_values(by=['mean_test_recall'],\n",
    "    ascending=[False]).index[0]]], axis=1)\n",
    "\n",
    "melhores_modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d4ca4d",
   "metadata": {},
   "source": [
    "### Modelo Vencedor\n",
    "- Parâmetros: {'n_neighbors': 33, 'p': 4, 'weights': 'uniform'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f413c837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>stat</th>\n",
       "      <th colspan=\"3\" halign=\"left\">valor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>list</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrica</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.793007</td>\n",
       "      <td>0.801238</td>\n",
       "      <td>0.784777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.746539</td>\n",
       "      <td>0.753825</td>\n",
       "      <td>0.739253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.730710</td>\n",
       "      <td>0.738396</td>\n",
       "      <td>0.723024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.730697</td>\n",
       "      <td>0.738409</td>\n",
       "      <td>0.722985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>[treino, teste]</td>\n",
       "      <td>0.705216</td>\n",
       "      <td>0.711710</td>\n",
       "      <td>0.698721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      stat     valor                    \n",
       "                      list      mean       max       min\n",
       "metrica                                                 \n",
       "recall     [treino, teste]  0.793007  0.801238  0.784777\n",
       "f1_score   [treino, teste]  0.746539  0.753825  0.739253\n",
       "accuracy   [treino, teste]  0.730710  0.738396  0.723024\n",
       "roc_auc    [treino, teste]  0.730697  0.738409  0.722985\n",
       "precision  [treino, teste]  0.705216  0.711710  0.698721"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricas_dict = {\n",
    "    'accuracy': accuracy_score,\n",
    "    'precision': precision_score,\n",
    "    'recall': recall_score,\n",
    "    'f1_score': f1_score,\n",
    "    'roc_auc': roc_auc_score\n",
    "}\n",
    "metricas_modelos = []\n",
    "\n",
    "X_treino,X_teste, y_treino,y_teste = train_test_split(n_features_data[0],y ,test_size=0.25, random_state=7) \n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=33, metric='minkowski')\n",
    "knn.fit(X_treino, y_treino)\n",
    "\n",
    "for metrica in ['accuracy', 'precision', 'recall', 'f1_score', 'roc_auc']:\n",
    "        metrica_avaliada_treino = metricas_dict[metrica](y_treino, knn.predict(X_treino))\n",
    "        metrica_avaliada_teste = metricas_dict[metrica](y_teste, knn.predict(X_teste))\n",
    "        metricas_modelos.append({'stat' : 'treino', 'metrica': metrica , 'valor': metrica_avaliada_treino})\n",
    "        metricas_modelos.append({'stat' : 'teste', 'metrica': metrica, 'valor': metrica_avaliada_teste})\n",
    "\n",
    "metricas_modelos = pd.DataFrame().from_records(metricas_modelos)\n",
    "\n",
    "#  Métricas do melhor modelo\n",
    "modelos = metricas_modelos.groupby(['metrica']).agg({'stat': list, 'valor': ['mean','max', 'min']})\n",
    "melhor_modelo = modelos.sort_values(\n",
    "    by=['metrica', ('valor', 'mean'),('valor', 'max'), ('valor', 'min')],\n",
    "    key=lambda x: (~x.str.contains('recall', case=False, na=False)) if x.name == 'metrica' else x, \n",
    "    ascending=[True,False,False,False])\n",
    "\n",
    "melhor_modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7b164",
   "metadata": {},
   "source": [
    "## Resultados \n",
    "- Considerando os métodos utilizados para equilibrar e tornar as features em PCA, e testar os modelos. Temos que as métrica indicam o modelo vencedor como possuidor dos melhores índices.\n",
    "- Comparando o modelo vencedor com os modelos iniciais temos que houve um aumento significativo, pelo menos 10%, em todos os indices com ecessao da acurácia, que diminuiu aproximadamente 12%. Isso significa que o balanceamento das classes targets e transformação de features em PCA foi efetiva, mas não o suficiente para resultar num modelo robusto e de alta confiança de acertos. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840df70d",
   "metadata": {},
   "source": [
    "### Métricas:\n",
    "- Acurácia: Indica os acertos pelo total das amostras. no modelo foi cerca de 73%, o que é um valor muito baixo para previsoes confiáveis, e pouco melhor que o lançar de uma moeda (50%).\n",
    "- Precisão: Indica a quantidade de acertos verdadeiro Positivos pelo soma de todos os valores positivos. Ou seja, a porcentagem de acertos verdadeiros sobre acertos verdadeiros e falsos. No modelo tem foi cerca de 70% o que indica ainda uma tendencia a classificar verdadeiro para diabetes no total de respostas já equilibradas em 50% de cada classe target.\n",
    "- Recall: Indica a quantidade de acertos verdadeiros positivos pelo total de amostras de teste positivas. Já o recall do modelo indica uma tendência aproximada de 80% de respostas verdadeiras positivas sobre todas as verdadeiras, o que indica um considerável retorno das amostras positivas, mas não o suficiente para se considerar num caso de diagnóstico clínico, pois a certeza necessaria para os casos deve ser muito alta, para não causar frustrações aos pacientes.\n",
    "- F1: media harmônica entre precisão e recall. No modelo representa mais um indicativo considerável, por ser a junção de duas métricas.\n",
    "- AUC: Uma curva ROC pode ser avaliada pela métrica AUC (Area Under the Curve ou “área sob a curva”). AUC calcula a área da forma bidimensional formada abaixo da curva. Essa métrica indica a probabilidade de duas previsões serem corretamente ranqueadas. A AUC será um valor entre 0 e 1. Quanto maior esse valor, melhor a capacidade do modelo em separar classes. O modelo possui um AUC aproximado de 78% o que é relativamente baixo para previsões em diagnósticos clínicos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82899453",
   "metadata": {},
   "source": [
    "### Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "672d7670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Matriz de Confusão - KNN Diabetes dataset')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matriz_confusao = confusion_matrix(y_teste, knn.predict(X_teste))\n",
    "mc = ConfusionMatrixDisplay(matriz_confusao)\n",
    "mc.plot()\n",
    "plt.title('Matriz de Confusão - KNN Diabetes dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d76309e",
   "metadata": {},
   "source": [
    "- a matriz de confusão mostra uma alta taxa de resultados erro nas previsões, apesar de o indice de verdadeiros positivos ser o mais relevante.\n",
    "- Para fins Clínicos o modelo não é confiável, pois tem de se considerar que em casos médicos e necessária uma precisão muito rigorosa para evitar frustrações ou procedimentos inadequados ao paciente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9669ebb6",
   "metadata": {},
   "source": [
    "### Conclusão:\n",
    "Os dados, apesar de serem em quantidade considerável, não conseguem representar adequadamente um padrão para que os classificadores, principalmente o KNN, consigam classificar adequadamente. Mesmo com a transformada PCA, própria para expressar melhor os dados com muitas variáveis, não foi suficiente para criar um modelo robusto para prever casos clínicos. Infelizmente é um problema de features não representativas para a classificação desejada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
